import os
import zipfile
import shutil
import tempfile
import random
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
import torch
from torch import nn, optim
from torch.utils.data import DataLoader, random_split
from torchvision import transforms, models, datasets
from sklearn.cluster import AgglomerativeClustering, KMeans
from sklearn.metrics import (adjusted_rand_score, normalized_mutual_info_score,
                             confusion_matrix, classification_report,
                             roc_auc_score, roc_curve)
from sklearn.preprocessing import label_binarize
from sklearn.decomposition import PCA
import streamlit as st
import gc
import logging
import base64
# Importa√ß√µes adicionais para Grad-CAM
from torchcam.methods import SmoothGradCAMpp
from torchvision.transforms.functional import normalize, resize, to_pil_image
import cv2
# Importa√ß√£o do m√≥dulo LLM Modal
from llm_modal import show_disease_modal, get_disease_key
# Definir o dispositivo (CPU ou GPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Configura√ß√µes para tornar os gr√°ficos mais bonitos
sns.set_style('whitegrid')

def set_seed(seed):
    """
    Define a seed para garantir a reprodutibilidade.
    """
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(42)  # Definir a seed para reprodutibilidade

# Definir as transforma√ß√µes para aumento de dados (aplicando transforma√ß√µes aleat√≥rias)
train_transforms = transforms.Compose([
    transforms.RandomApply([
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(degrees=90),
        transforms.ColorJitter(),
        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
        transforms.RandomAffine(degrees=0, shear=10),
    ], p=0.5),
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
])

# Transforma√ß√µes para valida√ß√£o e teste
test_transforms = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
])

# Dataset personalizado
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, dataset, transform=None):
        self.dataset = dataset
        self.transform = transform

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        image, label = self.dataset[idx]
        if self.transform:
            image = self.transform(image)
        return image, label

def seed_worker(worker_id):
    """
    Fun√ß√£o para definir a seed em cada worker do DataLoader.
    """
    worker_seed = torch.initial_seed() % 2**32
    np.random.seed(worker_seed)
    random.seed(worker_seed)

def visualize_data(dataset, classes):
    """
    Exibe algumas imagens do conjunto de dados com suas classes.
    """
    st.write("Visualiza√ß√£o de algumas imagens do conjunto de dados:")
    fig, axes = plt.subplots(1, 5, figsize=(15, 3))
    for i in range(5):
        idx = np.random.randint(len(dataset))
        image, label = dataset[idx]
        image = np.array(image)  # Converter a imagem PIL em array NumPy
        axes[i].imshow(image)
        axes[i].set_title(classes[label])
        axes[i].axis('off')
    st.pyplot(fig)

def plot_class_distribution(dataset, classes):
    """
    Exibe a distribui√ß√£o das classes no conjunto de dados e mostra os valores quantitativos.
    """
    # Extrair os r√≥tulos das classes para todas as imagens no dataset
    labels = [label for _, label in dataset]
    
    # Contagem de cada classe
    class_counts = np.bincount(labels)
    
    # Plotar o gr√°fico com as contagens
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.countplot(x=labels, ax=ax, palette="Set2")
    
    # Adicionar os nomes das classes no eixo X
    ax.set_xticklabels(classes, rotation=45)
    
    # Adicionar as contagens acima das barras
    for i, count in enumerate(class_counts):
        ax.text(i, count, str(count), ha='center', va='bottom', fontweight='bold')
    
    ax.set_title("Distribui√ß√£o das Classes (Quantidade de Imagens)")
    ax.set_xlabel("Classes")
    ax.set_ylabel("N√∫mero de Imagens")
    
    st.pyplot(fig)

def get_model(model_name, num_classes, dropout_p=0.5, fine_tune=False):
    """
    Retorna o modelo pr√©-treinado selecionado.
    """
    if model_name == 'ResNet18':
        model = models.resnet18(pretrained=True)
    elif model_name == 'ResNet50':
        model = models.resnet50(pretrained=True)
    elif model_name == 'DenseNet121':
        model = models.densenet121(pretrained=True)
    else:
        st.error("Modelo n√£o suportado.")
        return None

    if not fine_tune:
        for param in model.parameters():
            param.requires_grad = False

    if model_name.startswith('ResNet'):
        num_ftrs = model.fc.in_features
        model.fc = nn.Sequential(
            nn.Dropout(p=dropout_p),
            nn.Linear(num_ftrs, num_classes)
        )
    elif model_name.startswith('DenseNet'):
        num_ftrs = model.classifier.in_features
        model.classifier = nn.Sequential(
            nn.Dropout(p=dropout_p),
            nn.Linear(num_ftrs, num_classes)
        )
    else:
        st.error("Modelo n√£o suportado.")
        return None

    model = model.to(device)
    return model

def train_model(data_dir, num_classes, model_name, fine_tune, epochs, learning_rate, batch_size, train_split, valid_split, use_weighted_loss, l2_lambda, patience):
    """
    Fun√ß√£o principal para treinamento do modelo.
    """
    set_seed(42)

    # Carregar o dataset original sem transforma√ß√µes
    full_dataset = datasets.ImageFolder(root=data_dir)

    # Exibir algumas imagens do dataset
    visualize_data(full_dataset, full_dataset.classes)
    plot_class_distribution(full_dataset, full_dataset.classes)

    # Criar o dataset personalizado com aumento de dados
    train_dataset = CustomDataset(full_dataset, transform=train_transforms)
    valid_dataset = CustomDataset(full_dataset, transform=test_transforms)
    test_dataset = CustomDataset(full_dataset, transform=test_transforms)

    # Dividir os √≠ndices para treino, valida√ß√£o e teste
    dataset_size = len(full_dataset)
    indices = list(range(dataset_size))
    np.random.shuffle(indices)

    train_end = int(train_split * dataset_size)
    valid_end = int((train_split + valid_split) * dataset_size)

    train_indices = indices[:train_end]
    valid_indices = indices[train_end:valid_end]
    test_indices = indices[valid_end:]

    train_dataset = torch.utils.data.Subset(train_dataset, train_indices)
    valid_dataset = torch.utils.data.Subset(valid_dataset, valid_indices)
    test_dataset = torch.utils.data.Subset(test_dataset, test_indices)

    # Dataloaders
    g = torch.Generator()
    g.manual_seed(42)

    if use_weighted_loss:
        targets = [full_dataset.targets[i] for i in train_indices]
        class_counts = np.bincount(targets)
        class_counts = class_counts + 1e-6  # Para evitar divis√£o por zero
        class_weights = 1.0 / class_counts
        class_weights = torch.FloatTensor(class_weights).to(device)
        criterion = nn.CrossEntropyLoss(weight=class_weights)
    else:
        criterion = nn.CrossEntropyLoss()

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, worker_init_fn=seed_worker, generator=g)
    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, worker_init_fn=seed_worker, generator=g)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, worker_init_fn=seed_worker, generator=g)

    # Carregar o modelo
    model = get_model(model_name, num_classes, dropout_p=0.5, fine_tune=fine_tune)
    if model is None:
        return None

    # Definir o otimizador com L2 regularization (weight_decay)
    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate, weight_decay=l2_lambda)

    # Listas para armazenar as perdas e acur√°cias
    train_losses = []
    valid_losses = []
    train_accuracies = []
    valid_accuracies = []

    # Early Stopping
    best_valid_loss = float('inf')
    epochs_no_improve = 0

    # Treinamento
    for epoch in range(epochs):
        set_seed(42 + epoch)
        running_loss = 0.0
        running_corrects = 0
        model.train()

        for inputs, labels in train_loader:
            inputs = inputs.to(device)
            labels = labels.to(device)

            optimizer.zero_grad()
            try:
                outputs = model(inputs)
            except Exception as e:
                st.error(f"Erro durante o treinamento: {e}")
                return None

            _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == labels.data)

        epoch_loss = running_loss / len(train_dataset)
        epoch_acc = running_corrects.double() / len(train_dataset)
        train_losses.append(epoch_loss)
        train_accuracies.append(epoch_acc.item())

        # Valida√ß√£o
        model.eval()
        valid_running_loss = 0.0
        valid_running_corrects = 0

        with torch.no_grad():
            for inputs, labels in valid_loader:
                inputs = inputs.to(device)
                labels = labels.to(device)

                outputs = model(inputs)
                _, preds = torch.max(outputs, 1)
                loss = criterion(outputs, labels)

                valid_running_loss += loss.item() * inputs.size(0)
                valid_running_corrects += torch.sum(preds == labels.data)

        valid_epoch_loss = valid_running_loss / len(valid_dataset)
        valid_epoch_acc = valid_running_corrects.double() / len(valid_dataset)
        valid_losses.append(valid_epoch_loss)
        valid_accuracies.append(valid_epoch_acc.item())

        st.write(f'**√âpoca {epoch+1}/{epochs}**')
        st.write(f'Perda de Treino: {epoch_loss:.4f} | Acur√°cia de Treino: {epoch_acc:.4f}')
        st.write(f'Perda de Valida√ß√£o: {valid_epoch_loss:.4f} | Acur√°cia de Valida√ß√£o: {valid_epoch_acc:.4f}')

        # Early Stopping
        if valid_epoch_loss < best_valid_loss:
            best_valid_loss = valid_epoch_loss
            epochs_no_improve = 0
            best_model_wts = model.state_dict()
        else:
            epochs_no_improve += 1
            if epochs_no_improve >= patience:
                st.write('Early stopping!')
                model.load_state_dict(best_model_wts)
                break

    # Carregar os melhores pesos do modelo
    model.load_state_dict(best_model_wts)

    # Gr√°ficos de Perda e Acur√°cia
    plot_metrics(epochs, train_losses, valid_losses, train_accuracies, valid_accuracies)

    # Avalia√ß√£o Final no Conjunto de Teste
    st.write("**Avalia√ß√£o no Conjunto de Teste**")
    compute_metrics(model, test_loader, full_dataset.classes)

    # An√°lise de Erros
    st.write("**An√°lise de Erros**")
    error_analysis(model, test_loader, full_dataset.classes)

    # Liberar mem√≥ria
    del train_loader, valid_loader
    gc.collect()

    return model, full_dataset.classes

def plot_metrics(epochs, train_losses, valid_losses, train_accuracies, valid_accuracies):
    """
    Plota os gr√°ficos de perda e acur√°cia.
    """
    epochs_range = range(1, len(train_losses)+1)
    fig, ax = plt.subplots(1, 2, figsize=(14, 5))

    # Gr√°fico de Perda
    ax[0].plot(epochs_range, train_losses, label='Treino')
    ax[0].plot(epochs_range, valid_losses, label='Valida√ß√£o')
    ax[0].set_title('Perda por √âpoca')
    ax[0].set_xlabel('√âpocas')
    ax[0].set_ylabel('Perda')
    ax[0].legend()

    # Gr√°fico de Acur√°cia
    ax[1].plot(epochs_range, train_accuracies, label='Treino')
    ax[1].plot(epochs_range, valid_accuracies, label='Valida√ß√£o')
    ax[1].set_title('Acur√°cia por √âpoca')
    ax[1].set_xlabel('√âpocas')
    ax[1].set_ylabel('Acur√°cia')
    ax[1].legend()

    st.pyplot(fig)

def compute_metrics(model, dataloader, classes):
    """
    Calcula m√©tricas detalhadas e exibe matriz de confus√£o e relat√≥rio de classifica√ß√£o.
    """
    model.eval()
    all_preds = []
    all_labels = []
    all_probs = []

    with torch.no_grad():
        for inputs, labels in dataloader:
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model(inputs)
            probabilities = torch.nn.functional.softmax(outputs, dim=1)
            _, preds = torch.max(outputs, 1)

            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_probs.extend(probabilities.cpu().numpy())

    # Relat√≥rio de Classifica√ß√£o
    report = classification_report(all_labels, all_preds, target_names=classes, output_dict=True)
    st.text("Relat√≥rio de Classifica√ß√£o:")
    st.write(pd.DataFrame(report).transpose())

    # Matriz de Confus√£o Normalizada
    cm = confusion_matrix(all_labels, all_preds, normalize='true')
    fig, ax = plt.subplots()
    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=classes, yticklabels=classes, ax=ax)
    ax.set_xlabel('Predito')
    ax.set_ylabel('Verdadeiro')
    ax.set_title('Matriz de Confus√£o Normalizada')
    st.pyplot(fig)

    # Curva ROC
    if len(classes) == 2:
        fpr, tpr, thresholds = roc_curve(all_labels, [p[1] for p in all_probs])
        roc_auc = roc_auc_score(all_labels, [p[1] for p in all_probs])
        fig, ax = plt.subplots()
        ax.plot(fpr, tpr, label='AUC = %0.2f' % roc_auc)
        ax.plot([0, 1], [0, 1], 'k--')
        ax.set_xlabel('Taxa de Falsos Positivos')
        ax.set_ylabel('Taxa de Verdadeiros Positivos')
        ax.set_title('Curva ROC')
        ax.legend(loc='lower right')
        st.pyplot(fig)
    else:
        # Multiclasse
        binarized_labels = label_binarize(all_labels, classes=range(len(classes)))
        roc_auc = roc_auc_score(binarized_labels, np.array(all_probs), average='weighted', multi_class='ovr')
        st.write(f"AUC-ROC M√©dia Ponderada: {roc_auc:.4f}")

def error_analysis(model, dataloader, classes):
    """
    Realiza an√°lise de erros mostrando algumas imagens mal classificadas.
    """
    model.eval()
    misclassified_images = []
    misclassified_labels = []
    misclassified_preds = []

    with torch.no_grad():
        for inputs, labels in dataloader:
            inputs = inputs.to(device)
            labels = labels.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            incorrect = preds != labels
            if incorrect.any():
                misclassified_images.extend(inputs[incorrect].cpu())
                misclassified_labels.extend(labels[incorrect].cpu())
                misclassified_preds.extend(preds[incorrect].cpu())
                if len(misclassified_images) >= 5:
                    break

    if misclassified_images:
        st.write("Algumas imagens mal classificadas:")
        fig, axes = plt.subplots(1, min(5, len(misclassified_images)), figsize=(15, 3))
        for i in range(min(5, len(misclassified_images))):
            image = misclassified_images[i]
            image = image.permute(1, 2, 0).numpy()
            axes[i].imshow(image)
            axes[i].set_title(f"V: {classes[misclassified_labels[i]]}\nP: {classes[misclassified_preds[i]]}")
            axes[i].axis('off')
        st.pyplot(fig)
    else:
        st.write("Nenhuma imagem mal classificada encontrada.")

def extract_features(dataset, model, batch_size):
    """
    Extrai caracter√≠sticas de um conjunto de dados usando um modelo pr√©-treinado.
    """
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, worker_init_fn=seed_worker)

    features = []
    labels = []

    model.eval()
    with torch.no_grad():
        for inputs, lbls in dataloader:
            inputs = inputs.to(device)
            outputs = model(inputs)
            outputs = outputs.view(outputs.size(0), -1)  # Flatten
            features.append(outputs.cpu().numpy())
            labels.extend(lbls.numpy())

    features = np.concatenate(features, axis=0)
    labels = np.array(labels)
    return features, labels

def perform_clustering(features, num_clusters):
    """
    Aplica algoritmos de clustering √†s caracter√≠sticas.
    """
    # Clustering Hier√°rquico
    hierarchical = AgglomerativeClustering(n_clusters=num_clusters)
    hierarchical_labels = hierarchical.fit_predict(features)

    # K-Means
    kmeans = KMeans(n_clusters=num_clusters, random_state=42)
    kmeans_labels = kmeans.fit_predict(features)

    return hierarchical_labels, kmeans_labels

def evaluate_clustering(true_labels, cluster_labels, method_name):
    """
    Avalia os resultados do clustering comparando com as classes reais.
    """
    ari = adjusted_rand_score(true_labels, cluster_labels)
    nmi = normalized_mutual_info_score(true_labels, cluster_labels)
    st.write(f"**M√©tricas para {method_name}:**")
    st.write(f"Adjusted Rand Index: {ari:.4f}")
    st.write(f"Normalized Mutual Information Score: {nmi:.4f}")

def visualize_clusters(features, true_labels, hierarchical_labels, kmeans_labels, classes):
    """
    Visualiza os clusters usando redu√ß√£o de dimensionalidade e inclui as classes verdadeiras com nomes de r√≥tulos.
    """
    # Redu√ß√£o de dimensionalidade com PCA para visualizar os clusters em 2D
    pca = PCA(n_components=2)
    reduced_features = pca.fit_transform(features)

    # Mapear os r√≥tulos verdadeiros para os nomes das classes
    true_labels_named = [classes[label] for label in true_labels]
    
    # Usar as cores distintas e vis√≠veis para garantir que os clusters sejam claramente separados
    color_palette = sns.color_palette("tab10", len(set(true_labels)))

    fig, axes = plt.subplots(1, 3, figsize=(21, 6))  # Agora temos 3 gr√°ficos: Hierarchical, K-Means e classes verdadeiras

    # Clustering Hier√°rquico
    sns.scatterplot(x=reduced_features[:, 0], y=reduced_features[:, 1], hue=hierarchical_labels, palette="deep", ax=axes[0], legend='full')
    axes[0].set_title('Clustering Hier√°rquico')
    ari_hierarchical = adjusted_rand_score(true_labels, hierarchical_labels)
    nmi_hierarchical = normalized_mutual_info_score(true_labels, hierarchical_labels)
    axes[0].text(0.1, 0.9, f"ARI: {ari_hierarchical:.2f}\nNMI: {nmi_hierarchical:.2f}", horizontalalignment='center', verticalalignment='center', transform=axes[0].transAxes, bbox=dict(facecolor='white', alpha=0.5))

    # K-Means Clustering
    sns.scatterplot(x=reduced_features[:, 0], y=reduced_features[:, 1], hue=kmeans_labels, palette="deep", ax=axes[1], legend='full')
    axes[1].set_title('K-Means Clustering')
    ari_kmeans = adjusted_rand_score(true_labels, kmeans_labels)
    nmi_kmeans = normalized_mutual_info_score(true_labels, kmeans_labels)
    axes[1].text(0.1, 0.9, f"ARI: {ari_kmeans:.2f}\nNMI: {nmi_kmeans:.2f}", horizontalalignment='center', verticalalignment='center', transform=axes[1].transAxes, bbox=dict(facecolor='white', alpha=0.5))

    # Classes verdadeiras
    sns.scatterplot(x=reduced_features[:, 0], y=reduced_features[:, 1], hue=true_labels_named, palette=color_palette, ax=axes[2], legend='full')
    axes[2].set_title('Classes Verdadeiras')

    # Exibir os gr√°ficos
    st.pyplot(fig)

def evaluate_image(model, image, classes):
    """
    Avalia uma √∫nica imagem e retorna a classe predita e a confian√ßa.
    """
    model.eval()
    image_tensor = test_transforms(image).unsqueeze(0).to(device)
    with torch.no_grad():
        output = model(image_tensor)
        probabilities = torch.nn.functional.softmax(output, dim=1)
        confidence, predicted = torch.max(probabilities, 1)
        class_idx = predicted.item()
        class_name = classes[class_idx]
        return class_name, confidence.item()

#________________________________________________

def visualize_activations(model, image, class_names):
    """
    Visualiza as ativa√ß√µes na imagem usando Grad-CAM.
    """
    model.eval()  # Coloca o modelo em modo de avalia√ß√£o
    input_tensor = test_transforms(image).unsqueeze(0).to(device)
    
    # Verificar se o modelo √© suportado
    if isinstance(model, models.ResNet):
        target_layer = model.layer4[-1]
    elif isinstance(model, models.DenseNet):
        target_layer = model.features.denseblock4.denselayer16
    else:
        st.error("Modelo n√£o suportado para Grad-CAM.")
        return
    
    # Criar o objeto CAM usando torchcam
    cam_extractor = SmoothGradCAMpp(model, target_layer=target_layer)
    
    # Habilitar gradientes explicitamente
    with torch.set_grad_enabled(True):
        out = model(input_tensor)  # Faz a previs√£o
        _, pred = torch.max(out, 1)  # Obt√©m a classe predita
        pred_class = pred.item()
    
    # Gerar o mapa de ativa√ß√£o
    activation_map = cam_extractor(pred_class, out)
    
    # Obter o mapa de ativa√ß√£o da primeira imagem no lote
    activation_map = activation_map[0].cpu().numpy()
    
    # Redimensionar o mapa de ativa√ß√£o para coincidir com o tamanho da imagem original
    activation_map_resized = cv2.resize(activation_map, (image.size[0], image.size[1]))
    
    # Normalizar o mapa de ativa√ß√£o para o intervalo [0, 1]
    activation_map_resized = (activation_map_resized - activation_map_resized.min()) / (activation_map_resized.max() - activation_map_resized.min())
    
    # Converter a imagem para array NumPy
    image_np = np.array(image)
    
    # Converter o mapa de ativa√ß√£o em uma imagem RGB
    heatmap = cv2.applyColorMap(np.uint8(255 * activation_map_resized), cv2.COLORMAP_JET)
    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)
    
    # Sobrepor o mapa de ativa√ß√£o na imagem original
    superimposed_img = heatmap * 0.4 + image_np * 0.6
    superimposed_img = np.uint8(superimposed_img)
    
    # Exibir a imagem original e o mapa de ativa√ß√£o sobreposto
    fig, ax = plt.subplots(1, 2, figsize=(10, 5))
    
    # Imagem original
    ax[0].imshow(image_np)
    ax[0].set_title('Imagem Original')
    ax[0].axis('off')
    
    # Imagem com Grad-CAM
    ax[1].imshow(superimposed_img)
    ax[1].set_title('Grad-CAM')
    ax[1].axis('off')
    
    # Exibir as imagens com o Streamlit
    st.pyplot(fig)



def main():

    # Definir o caminho do √≠cone
    icon_path = "logo.png"  # Verifique se o arquivo logo.png est√° no diret√≥rio correto
    
    # Verificar se o arquivo de √≠cone existe antes de configur√°-lo
    if os.path.exists(icon_path):
        st.set_page_config(page_title="OdontoIA", page_icon=icon_path, layout="wide")
        logging.info(f"√çcone {icon_path} carregado com sucesso.")
    else:
        # Se o √≠cone n√£o for encontrado, carrega sem favicon
        st.set_page_config(page_title="OdontoIA", layout="wide")
        logging.warning(f"√çcone {icon_path} n√£o encontrado, carregando sem favicon.")
    
    # Layout da p√°gina
    if os.path.exists('capa.png'):
        st.image('capa.png', width=100, caption='Laborat√≥rio de Educa√ß√£o e Intelig√™ncia Artificial - Geomaker. "A melhor forma de prever o futuro √© invent√°-lo." - Alan Kay', use_column_width='always')
    else:
        st.warning("Imagem 'capa.png' n√£o encontrada.")
    
    if os.path.exists("logo.png"):
        st.sidebar.image("logo.png", width=200)
    else:
        st.sidebar.text("Imagem do logotipo n√£o encontrada.")
    
    
  #___________________________________________________________
    st.title("Detec√ß√£o de les√µes por Imagens com Aprendizado Profundo")
    st.write("Este aplicativo permite treinar um modelo de classifica√ß√£o de imagens e aplicar algoritmos de clustering para an√°lise comparativa.")
    
    # Nova se√ß√£o sobre o modal LLM
    with st.expander("üÜï **Novo Recurso: Consulta Acad√™mica Inteligente com IA**", expanded=False):
        st.markdown("""
        ### ü§ñ Sistema de Consulta Acad√™mica Integrado
        
        Este sistema agora inclui um **m√≥dulo de intelig√™ncia artificial** que oferece:
        
        #### üìö **Descri√ß√µes Cl√≠nicas Detalhadas**
        - Informa√ß√µes m√©dicas precisas sobre cada doen√ßa bucal
        - Sintomas, causas e tratamentos baseados em literatura cient√≠fica
        - Terminologia m√©dica apropriada para profissionais da sa√∫de
        
        #### üî¨ **Refer√™ncias do PubMed**
        - Busca autom√°tica de artigos cient√≠ficos relevantes
        - Integra√ß√£o direta com a base de dados PubMed/MEDLINE
        - Acesso a abstracts e links para artigos completos
        - Refer√™ncias atualizadas para suporte √† pr√°tica cl√≠nica
        
        #### üéØ **An√°lise Inteligente**
        - Insights cl√≠nicos gerados por IA
        - Correla√ß√µes entre achados visuais e manifesta√ß√µes cl√≠nicas
        - Suporte √† tomada de decis√£o diagn√≥stica
        
        #### üöÄ **Como Usar**
        1. **Durante o treinamento:** Explore informa√ß√µes sobre as 7 classes de doen√ßas bucais no painel lateral
        2. **Ap√≥s a predi√ß√£o:** Clique em "Ver Informa√ß√µes" para detalhes acad√™micos da doen√ßa identificada
        3. **Consulta independente:** Use o seletor no painel lateral para estudar qualquer doen√ßa
        
        > ‚ö†Ô∏è **Importante:** Este recurso √© destinado a fins educacionais e de suporte cl√≠nico. 
        > Sempre consulte um profissional qualificado para diagn√≥stico e tratamento.
        """)
    
    with st.expander("Transforma√ß√µes de Dados e Aumento de Dados no Treinamento de Redes Neurais"):
        st.write("""
        As **transforma√ß√µes de dados** e o **aumento de dados** s√£o t√©cnicas essenciais no treinamento de redes neurais profundas, principalmente em tarefas de vis√£o computacional. 
        Essas abordagens buscam melhorar a capacidade de generaliza√ß√£o dos modelos, gerando **imagens sint√©ticas** a partir dos dados de treinamento. Tais t√©cnicas s√£o particularmente 
        valiosas quando o conjunto de dados dispon√≠vel √© pequeno ou apresenta pouca diversidade. A normaliza√ß√£o, por sua vez, assegura que os valores dos pixels estejam em uma escala adequada, 
        resultando em um treinamento mais est√°vel e eficiente. Diversos estudos apontam que essas pr√°ticas s√£o eficazes para evitar **overfitting** e aumentar a robustez do modelo 
        (Shorten & Khoshgoftaar, 2019).
        """)
    
        st.write("### Aumento de Dados no Treinamento")
    
        st.write("""
        O **aumento de dados** ou *data augmentation* consiste na aplica√ß√£o de transforma√ß√µes aleat√≥rias √†s imagens do conjunto de treinamento para gerar novas amostras sint√©ticas. 
        No c√≥digo implementado, essa t√©cnica √© realizada com a classe `transforms.Compose` da biblioteca **torchvision**, que aplica uma sequ√™ncia de transforma√ß√µes.
        """)
    
        st.write("#### Transforma√ß√µes Aplicadas no Treinamento")
        
        st.write("""
        1. **RandomApply**: Aplica aleatoriamente um conjunto de transforma√ß√µes com 50% de probabilidade. Esse procedimento aumenta a variabilidade dos dados, gerando imagens diferentes a partir de uma √∫nica imagem de entrada.
       
        2. **RandomHorizontalFlip**: Realiza a invers√£o horizontal da imagem com 50% de probabilidade. Isso √© √∫til em cen√°rios onde a orienta√ß√£o horizontal da imagem n√£o altera seu significado, como em imagens de rochas ou melanomas.
    
        3. **RandomRotation(degrees=90)**: Rotaciona a imagem em at√© 90 graus, criando varia√ß√µes angulares, o que ajuda o modelo a reconhecer objetos independentemente da orienta√ß√£o.
    
        4. **ColorJitter**: Introduz varia√ß√µes de brilho, contraste, satura√ß√£o e matiz, simulando diferentes condi√ß√µes de ilumina√ß√£o e tornando o modelo mais robusto a mudan√ßas de ilumina√ß√£o.
    
        5. **RandomResizedCrop(224, scale=(0.8, 1.0))**: Realiza cortes aleat√≥rios na imagem e os redimensiona para 224x224 pixels, permitindo que diferentes partes da imagem sejam enfatizadas.
    
        6. **RandomAffine(degrees=0, shear=10)**: Aplica transforma√ß√µes afins, como cisalhamento, simulando distor√ß√µes que podem ocorrer no mundo real, como mudan√ßas de perspectiva.
    
        7. **Resize(256)**: Redimensiona a imagem para 256x256 pixels, assegurando que todas as imagens possuam a mesma dimens√£o.
    
        8. **CenterCrop(224)**: Recorta o centro da imagem, garantindo que o tamanho final seja 224x224 pixels.
    
        9. **ToTensor**: Converte a imagem para um tensor PyTorch, normalizando os valores dos pixels para o intervalo de [0,1], facilitando o processamento pelo modelo.
        """)
    
        st.write("### Gera√ß√£o de Imagens Sint√©ticas")
    
        st.write("""
        Essas transforma√ß√µes permitem que cada imagem original gere at√© **5 a 10 imagens sint√©ticas**. Por exemplo, em um conjunto de dados de 1000 imagens, 
        o processo pode expandir o conjunto para **5000 a 10000 imagens** ao longo do treinamento. Essa amplia√ß√£o artificial do conjunto de dados reduz o risco de **overfitting**, 
        permitindo que o modelo treine em um conjunto "maior" e mais diverso, o que √© crucial para melhorar a generaliza√ß√£o do modelo em dados novos.
        """)
    
        st.write("### Normaliza√ß√£o nas Imagens de Teste e Valida√ß√£o")
    
        st.write("""
        Nas imagens de **teste** e **valida√ß√£o**, o aumento de dados n√£o √© aplicado. O objetivo nesses conjuntos √© avaliar o modelo de maneira consistente, 
        utilizando imagens que representem o mais fielmente poss√≠vel os dados reais. No entanto, a normaliza√ß√£o dessas imagens √© fundamental para assegurar que seus valores de pixel 
        estejam adequados para as opera√ß√µes de aprendizado. Isso tamb√©m garante um desempenho est√°vel durante o treinamento.
        """)
    
        st.write("#### Transforma√ß√µes Aplicadas no Teste e Valida√ß√£o")
        
        st.write("""
        1. **Resize(256)**: Redimensiona a imagem para 256x256 pixels, garantindo que todas as imagens tenham o mesmo tamanho inicial.
    
        2. **CenterCrop(224)**: Realiza o corte central para que as dimens√µes da imagem sejam 224x224 pixels, correspondendo ao tamanho esperado pelo modelo.
    
        3. **ToTensor**: Converte a imagem para tensor e normaliza os valores dos pixels para o intervalo de [0,1], o que melhora a estabilidade num√©rica e a taxa de converg√™ncia do treinamento.
        """)
    
        st.write("### Import√¢ncia da Normaliza√ß√£o")
    
        st.write("""
        A **normaliza√ß√£o** garante que os valores dos pixels estejam em uma escala apropriada para as opera√ß√µes aritm√©ticas realizadas no modelo, melhorando a estabilidade e o desempenho do processo de treinamento. 
        Ela tamb√©m contribui para a estabilidade num√©rica durante o c√°lculo do gradiente e para uma converg√™ncia mais eficiente do modelo (Nguy·ªÖn et al., 2021).
        """)
    
        st.write("### Conclus√£o")
    
        st.write("""
        O c√≥digo exemplifica a implementa√ß√£o eficaz de transforma√ß√µes de dados e aumento de dados como parte da pipeline de treinamento de redes neurais profundas. 
        As transforma√ß√µes aplicadas aumentam a diversidade do conjunto de treinamento, ajudando a mitigar o **overfitting** e melhorar a generaliza√ß√£o do modelo. 
        Al√©m disso, a normaliza√ß√£o aplicada aos dados de teste e valida√ß√£o garante que o desempenho do modelo seja avaliado de forma precisa e consistente, 
        alinhada √†s melhores pr√°ticas de aprendizado profundo.
        """)
    
        st.write("### Refer√™ncias")
        
        st.write("""
        - Huang, G., Liu, Z., Maaten, L., & Weinberger, K. (2017). Densely connected convolutional networks. https://doi.org/10.1109/cvpr.2017.243
        - Li, S. (2023). Clouddensenet: lightweight ground-based cloud classification method for large-scale datasets based on reconstructed densenet. *Sensors*, 23(18), 7957. https://doi.org/10.3390/s23187957
        - Nguy·ªÖn, H., Yu, G., Shin, N., Kwon, G., Kwak, W., & Kim, J. (2021). Defective product classification system for smart factory based on deep learning. *Electronics*, 10(7), 826. https://doi.org/10.3390/electronics10070826
        - Shorten, C. & Khoshgoftaar, T. M. (2019). A survey on image data augmentation for deep learning. *Journal of Big Data*, 6(1). https://doi.org/10.1186/s40537-019-0197-0
        """)

    # Barra Lateral de Configura√ß√µes
    st.sidebar.title("Configura√ß√µes do Treinamento")
      # Imagem e Contatos___________________________
    #_______________________________________________________________________________________
    # Sidebar com o conte√∫do explicativo e f√≥rmulas LaTeX
    with st.sidebar:
        with st.expander("Discuss√£o sobre o N√∫mero de Classes em Modelos de Aprendizado Profundo"):
            st.write("""
            ### Introdu√ß√£o
    
            A discuss√£o sobre o n√∫mero de classes em modelos de aprendizado profundo √© fundamental para a compreens√£o da arquitetura e do desempenho de redes neurais em tarefas de classifica√ß√£o. O n√∫mero de classes refere-se ao total de categorias ou r√≥tulos que um modelo deve prever, e a configura√ß√£o correta desse par√¢metro impacta diretamente o desempenho do modelo, pois afeta a dimens√£o da sa√≠da da rede neural e a complexidade da tarefa. O n√∫mero de classes pode variar de tarefas bin√°rias, que envolvem apenas duas classes, at√© problemas com centenas ou milhares de classes, como nas classifica√ß√µes de imagens do **ImageNet** (Cheng, 2023).
            """)
    
            st.write("### Impacto do N√∫mero de Classes")
            st.write("""
            O n√∫mero de classes define a estrutura da √∫ltima camada da rede neural, que √© respons√°vel por realizar as predi√ß√µes. Para um problema de **classifica√ß√£o bin√°ria**, o modelo ter√° uma √∫nica sa√≠da que prev√™ a probabilidade de uma classe ou outra. Em contrapartida, em um problema de **classifica√ß√£o multiclasse**, o n√∫mero de sa√≠das ser√° igual ao n√∫mero de categorias poss√≠veis (Cheng, 2023). A fun√ß√£o de ativa√ß√£o utilizada na √∫ltima camada √© crucial para a interpreta√ß√£o dos resultados. A equa√ß√£o que representa essa rela√ß√£o pode ser expressa como:
            """)
            st.latex(r'''
            \mathbf{y} = \text{Softmax}(Wx + b)
            ''')
    
            st.write("""
            onde **W** e **b** s√£o os pesos e o bias, respectivamente, que conectam a camada anterior √†s classes de sa√≠da. O resultado √© passado pela fun√ß√£o **softmax**, que converte os valores em probabilidades associadas a cada classe (Petrovska et al., 2020).
            """)
    
                       
            st.write("""
            Em tarefas de classifica√ß√£o bin√°ria, o modelo tem apenas duas classes poss√≠veis, como **detec√ß√£o de fraude** ou **diagn√≥stico de doen√ßas** (positivo ou negativo). Nesse caso, a fun√ß√£o de ativa√ß√£o final √© geralmente a **sigmoide**, que retorna uma probabilidade entre 0 e 1 para cada entrada. Um limiar √© ent√£o aplicado para decidir a classe final predita pelo modelo (Cheng, 2023).
            """)
    
            st.write("### Classifica√ß√£o Multiclasse")
            st.write("""
            Em problemas de classifica√ß√£o multiclasse, o n√∫mero de classes pode variar consideravelmente. Por exemplo, em tarefas de **classifica√ß√£o de imagens geol√≥gicas**, o n√∫mero de classes pode ser pequeno, mas em aplica√ß√µes como a **classifica√ß√£o de imagens m√©dicas** ou **reconhecimento facial**, o n√∫mero de classes pode ser muito maior. A arquitetura da rede deve ser ajustada para garantir que a √∫ltima camada tenha o n√∫mero correto de sa√≠das correspondente ao n√∫mero de categorias (Cheng, 2023; Sardeshmukh, 2023).
            """)
    
            st.write("### Classifica√ß√£o Multirr√≥tulo")
            st.write("""
            Em problemas de **classifica√ß√£o multirr√≥tulo**, uma entrada pode pertencer a mais de uma classe ao mesmo tempo. Nesse cen√°rio, o n√∫mero de sa√≠das da rede neural √© igual ao n√∫mero de classes poss√≠veis, mas cada sa√≠da √© independente das demais. A fun√ß√£o de ativa√ß√£o usada √© a **sigmoide**, pois ela calcula a probabilidade de cada classe independentemente das outras (Petrovska et al., 2020).
            """)
    
            st.write("### Efeitos do N√∫mero de Classes no Desempenho")
            st.write("""
            O n√∫mero de classes influencia diretamente a complexidade do modelo e o tempo de treinamento. Conforme o n√∫mero de classes aumenta, a tarefa de classifica√ß√£o se torna mais dif√≠cil, exigindo mais par√¢metros e tempo de computa√ß√£o. Al√©m disso, um maior n√∫mero de classes aumenta o risco de **sobreajuste** (overfitting), especialmente em conjuntos de dados pequenos (Cheng, 2023; Suhana, 2022).
            """)
    
            st.write("### Conclus√£o")
            st.write("""
            O n√∫mero de classes √© um fator determinante na defini√ß√£o da arquitetura de redes neurais para tarefas de classifica√ß√£o. Seja em problemas bin√°rios, multiclasse ou multirr√≥tulo, a escolha adequada desse par√¢metro garante que a rede neural seja capaz de aprender as caracter√≠sticas relevantes de cada categoria. Em problemas com muitas classes, estrat√©gias como a **regulariza√ß√£o** e o **data augmentation** podem ser utilizadas para melhorar o desempenho do modelo, evitando o sobreajuste (Cheng, 2023; Sardeshmukh, 2023).
            """)
    
            st.write("### Refer√™ncias")
          
            st.write("""
            1. Cheng, R. (2023). Expansion of the CT-scans image set based on the pretrained DCGAN for improving the performance of the CNN. *Journal of Physics Conference Series*, 2646(1), 012015. https://doi.org/10.1088/1742-6596/2646/1/012015
            2. Petrovska, B., Atanasova-Pacemska, T., Corizzo, R., Mignone, P., Lameski, P., & Zdravevski, E. (2020). Aerial Scene Classification through Fine-Tuning with Adaptive Learning Rates and Label Smoothing. *Applied Sciences*, 10(17), 5792. https://doi.org/10.3390/app10175792
            3. Sardeshmukh, M. (2023). Crop image classification using convolutional neural network. *Multidisciplinary Science Journal*, 5(4), 2023039. https://doi.org/10.31893/multiscience.2023039
            4. Suhana, R. (2022). Fish Image Classification Using Adaptive Learning Rate In Transfer Learning Method. *Knowledge Engineering and Data Science*, 5(1), 67-77. https://doi.org/10.17977/um018v5i12022p67-77
            """)

  
    num_classes = st.sidebar.number_input("N√∫mero de Classes:", min_value=1, step=1)
    #_______________________________________________________________________________________
    # Sidebar com o conte√∫do explicativo e f√≥rmula LaTeX
    with st.sidebar:
        with st.expander("Modelos Pr√©-Treinados: ResNet18, ResNet50 e DenseNet121:"):
            st.write("""
            ### Introdu√ß√£o
        
            As redes neurais convolucionais (CNNs) t√™m se tornado uma ferramenta essencial no campo do aprendizado profundo, especialmente em tarefas de vis√£o computacional, como a classifica√ß√£o de imagens. 
            Modelos como **ResNet18**, **ResNet50** e **DenseNet121** s√£o amplamente reconhecidos por seu desempenho superior em competi√ß√µes de classifica√ß√£o de imagens, como o **ImageNet**. Esses modelos s√£o considerados 
            **pr√©-treinados**, pois foram inicialmente treinados em grandes conjuntos de dados, permitindo que sejam reutilizados e ajustados para novas tarefas espec√≠ficas, uma pr√°tica conhecida como **transfer√™ncia de aprendizado** 
            (Cheng, 2023; Petrovska et al., 2020; Alaoui, 2023).
            """)
        
            st.write("### ResNet18 e ResNet50")
            st.write("""
            A arquitetura **ResNet** (Rede Residual) foi desenvolvida para mitigar o problema de **degrada√ß√£o** que ocorre em redes neurais muito profundas, onde o aumento do n√∫mero de camadas pode levar a uma diminui√ß√£o no desempenho.
            A inova√ß√£o dos **blocos residuais** permite que algumas camadas "saltem" conex√µes, aprendendo uma **fun√ß√£o de identidade** em vez de novas representa√ß√µes para cada camada. Essa abordagem facilita o treinamento de redes mais profundas, pois a fun√ß√£o residual pode ser aprendida de forma mais eficiente (Zhang et al., 2018; Sandotra et al., 2023; Petrovska et al., 2020).
            """)
            
            st.latex(r'''
            \mathbf{y} = \mathcal{F}(x, \{W_i\}) + x
            ''')
            
            st.write("""
            onde 
            """)
            st.latex(r'''
            \mathcal{F}(x, \{W_i\}) + x
            ''')
          
            st.write("""
            representa a fun√ß√£o aprendida e x √© a entrada. O termo x √© adicionado √† sa√≠da, o que simplifica o processo de treinamento e permite que redes mais profundas sejam treinadas com maior efic√°cia 
            ("A Framework for Flood Extent Mapping using CNN Transfer Learning", 2022; Petrovska et al., 2020).
            """)
        
            st.write("""
            O modelo **ResNet18** possui 18 camadas trein√°veis e √© uma vers√£o mais leve, adequada para aplica√ß√µes com restri√ß√µes de recursos computacionais, enquanto o **ResNet50**, com 50 camadas, √© capaz de capturar padr√µes mais complexos em imagens, sendo ideal para tarefas que exigem maior profundidade de an√°lise (Sandotra et al., 2023; Qin et al., 2019; Petrovska et al., 2020).
            """)
        
            st.write("""
            Ambos os modelos foram pr√©-treinados no conjunto de dados **ImageNet**, o que facilita a **transfer√™ncia de aprendizado** em novos dom√≠nios. As camadas iniciais desses modelos j√° s√£o capazes de identificar caracter√≠sticas gerais, acelerando o processo de treinamento em conjuntos de dados menores e espec√≠ficos, como em aplica√ß√µes m√©dicas ou de classifica√ß√£o de imagens geol√≥gicas (Cheng, 2023; Petrovska et al., 2020; Alaoui, 2023).
            """)
        
            st.write("### DenseNet121")
            st.write("""
            A arquitetura **DenseNet** (Rede Convolucional Densamente Conectada) oferece uma abordagem alternativa, onde todas as camadas est√£o interconectadas, promovendo a preserva√ß√£o do fluxo de gradiente e da informa√ß√£o original. Isso facilita a reutiliza√ß√£o das representa√ß√µes intermedi√°rias e otimiza a efici√™ncia do modelo. A equa√ß√£o que expressa essa estrutura √©:
            """)
        
            st.latex(r'''
            \mathbf{x}_l = H_l(\mathbf{x}_0, \mathbf{x}_1, \dots, \mathbf{x}_{l-1})
            ''')
        
            st.write("""
            onde
            """)
          
            st.latex(r'''
            \mathbf{x}_l 
            ''')
          
            st.write("""
            √© a sa√≠da da l-√©sima camada e 
            """)
          
            st.latex(r'''
             \mathbf{H}_l
            ''')
          
            st.write("""
            √© a fun√ß√£o aplicada. Essa configura√ß√£o otimiza o uso de gradientes e representa√ß√µes, resultando em um desempenho superior em tarefas de classifica√ß√£o 
            (Benegui & Ionescu, 2020; Varshni et al., 2019; Hamdaoui et al., 2021).
            """)
        
            st.write("""
            O modelo **DenseNet121**, que possui 121 camadas trein√°veis, √© particularmente eficaz em contextos onde a efici√™ncia √© crucial, maximizando o uso de recursos computacionais e facilitando a extra√ß√£o de caracter√≠sticas relevantes de imagens (Sardeshmukh, 2023; Hamdaoui et al., 2021).
            """)
        
            st.write("### Transfer√™ncia de Aprendizado e Ajuste Fino")
            st.write("""
            A utiliza√ß√£o de modelos pr√©-treinados, como ResNet18, ResNet50 e DenseNet121, √© uma t√©cnica de **transfer√™ncia de aprendizado** que permite que o conhecimento adquirido em tarefas anteriores seja aplicado a novos problemas. 
            Em vez de treinar um modelo do zero, o ajuste fino √© realizado nas camadas do modelo para se adaptar a um novo conjunto de dados, permitindo que caracter√≠sticas espec√≠ficas sejam aprendidas de forma mais eficiente. Por exemplo, em aplica√ß√µes de **classifica√ß√£o de melanomas** ou **an√°lise de rochas vulc√¢nicas**, as camadas mais profundas dos modelos s√£o ajustadas para entender caracter√≠sticas espec√≠ficas de imagens m√©dicas ou geol√≥gicas (Suhana, 2022; Petrovska et al., 2020).
            """)
        
            st.write("""
            Estudos demonstram que a transfer√™ncia de aprendizado √© especialmente eficaz ao se trabalhar com conjuntos de dados pequenos. O uso de modelos pr√©-treinados pode proporcionar resultados semelhantes ou at√© superiores aos de modelos treinados a partir do zero, reduzindo o tempo de treinamento e melhorando a precis√£o (Raghava et al., 2019; Alaoui, 2023; Ahmed, 2021).
            """)
        
            st.write("### Conclus√£o")
            st.write("""
            As arquiteturas **ResNet18**, **ResNet50** e **DenseNet121** s√£o ferramentas poderosas no campo do aprendizado profundo, especialmente em tarefas de classifica√ß√£o de imagens. Seu pr√©-treinamento em grandes conjuntos de dados, como o **ImageNet**, e a capacidade de serem ajustados para novas tarefas atrav√©s da transfer√™ncia de aprendizado, tornam esses modelos ideais para uma ampla gama de aplica√ß√µes, incluindo a classifica√ß√£o de imagens m√©dicas e geol√≥gicas. O uso dessas arquiteturas n√£o apenas reduz o tempo de treinamento, mas tamb√©m melhora a precis√£o e a efic√°cia em diversas √°reas de pesquisa e aplica√ß√£o pr√°tica (Zeimarani et al., 2020; "Dog Breed Identification with Fine Tuning of Pre-trained Models", 2019; Awais et al., 2020).
            """)
        
            st.write("### Refer√™ncias")
        
            st.write("""
            - (2019). Dog breed identification with fine tuning of pre-trained models. *International Journal of Recent Technology and Engineering*, 8(2S11), 3677-3680. https://doi.org/10.35940/ijrte.b1464.0982s1119
            - (2022). A framework for flood extent mapping using cnn transfer learning. https://doi.org/10.17762/ijisae.v10i3s.2426
            - Ahmed, A. (2021). Pre-trained cnns models for content based image retrieval. *International Journal of Advanced Computer Science and Applications*, 12(7). https://doi.org/10.14569/ijacsa.2021.0120723
            - Alaoui, A. (2023). Pre-trained cnns: evaluating emergency vehicle image classification. *Data & Metadata*, 2, 153. https://doi.org/10.56294/dm2023153
            - Benegui, C. and Ionescu, R. (2020). Convolutional neural networks for user identification based on motion sensors represented as images. *IEEE Access*, 8, 61255-61266. https://doi.org/10.1109/access.2020.2984214
            - Cheng, R. (2023). Expansion of the ct-scans image set based on the pretrained dcgan for improving the performance of the cnn. *Journal of Physics Conference Series*, 2646(1), 012015. https://doi.org/10.1088/1742-6596/2646/1/012015
            - Hamdaoui, H., Ben-fares, A., Boujraf, S., Chaoui, N., Alami, B., Ma√¢roufi, M., ‚Ä¶ & Qjidaa, H. (2021). High precision brain tumor classification model based on deep transfer learning and stacking concepts. *Indonesian Journal of Electrical Engineering and Computer Science*, 24(1), 167. https://doi.org/10.11591/ijeecs.v24.i1.pp167-177
            - Petrovska, B., Atanasova-Pacemska, T., Corizzo, R., Mignone, P., Lameski, P., & Zdravevski, E. (2020). Aerial scene classification through fine-tuning with adaptive learning rates and label smoothing. *Applied Sciences*, 10(17), 5792. https://doi.org/10.3390/app10175792
            - Raghava, Y., Kuthadi, V., & Rajalakshmi, S. (2019). Enhanced deep learning with featured transfer learning in identifying disguised faces. *International Journal of Innovative Technology and Exploring Engineering*, 8(10), 1257-1260. https://doi.org/10.35940/ijitee.h7286.0881019
            - Sandotra, N., Mahajan, P., Abrol, P., & Lehana, P. (2023). Analyzing performance of deep learning models under the presence of distortions in identifying plant leaf disease. *International Journal of Informatics and Communication Technology (IJ-ICT)*, 12(2), 115. https://doi.org/10.11591/ijict.v12i2.pp115-126
            - Sardeshmukh, M. (2023). Crop image classification using convolutional neural network. *Multidisciplinary Science Journal*, 5(4), 2023039. https://doi.org/10.31893/multiscience.2023039
            - Suhana, R. (2022). Fish image classification using adaptive learning rate in transfer learning method. *Knowledge Engineering and Data Science*, 5(1), 67. https://doi.org/10.17977/um018v5i12022p67-77
            - Varshni, D., Thakral, K., Agarwal, L., Nijhawan, R., & Mittal, A. (2019). Pneumonia detection using cnn based feature extraction. https://doi.org/10.1109/icecct.2019.8869364
            - Zeimarani, B., Costa, M., Nurani, N., Bianco, S., Pereira, W., & Filho, C. (2020). Breast lesion classification in ultrasound images using deep convolutional neural network. *IEEE Access*, 8, 133349-133359. https://doi.org/10.1109/access.2020.3010863
            - Zhang, B., Wang, C., Shen, Y., & Liu, Y. (2018). Fully connected conditional random fields for high-resolution remote sensing land use/land cover classification with convolutional neural networks. *Remote Sensing*, 10(12), 1889. https://doi.org/10.3390/rs10121889
            """)

    model_name = st.sidebar.selectbox("Modelo Pr√©-treinado:", options=['ResNet18', 'ResNet50', 'DenseNet121'])

    #________________________________________________________________________________________
    # Fine-Tuning Completo em Redes Neurais Profundas
    with st.sidebar:
        with st.expander("Fine-Tuning Completo em Redes Neurais Profundas:"):
            st.write("""
            ### Introdu√ß√£o
        
            O **fine-tuning** (ajuste fino) √© uma t√©cnica poderosa utilizada para ajustar redes neurais pr√©-treinadas em novos conjuntos de dados. No contexto de redes como a **ResNet18**, **ResNet50** ou **DenseNet121**, que foram inicialmente treinadas em grandes bases de dados (como o **ImageNet**), o fine-tuning permite que essas redes sejam adaptadas a novos problemas, como a **classifica√ß√£o de melanomas** ou de **rochas vulc√¢nicas e plut√¥nicas**. Ao realizar o fine-tuning, todas as camadas do modelo s√£o atualizadas para refletir as caracter√≠sticas do novo conjunto de dados, ao inv√©s de congelar as camadas iniciais, o que permite uma adapta√ß√£o mais profunda e precisa ao novo problema (Piotrowski & Napiorkowski, 2013; Friedrich et al., 2022).
            """)
        
            st.write("""
            ### Fundamenta√ß√£o Te√≥rica
        
            O conceito de fine-tuning √© baseado no princ√≠pio de **transfer√™ncia de aprendizado**, no qual um modelo pr√©-treinado em um grande conjunto de dados gen√©ricos √© reaproveitado para um novo problema espec√≠fico. Essa abordagem √© particularmente √∫til quando o novo conjunto de dados √© relativamente pequeno, pois o modelo j√° foi treinado para capturar padr√µes gerais em dados visuais (como bordas, texturas e formas), o que pode acelerar o treinamento e melhorar a precis√£o final (Al‚Äêrimy et al., 2023; Sakizadeh et al., 2015).
            """)
        
            st.write("""
            Ao utilizar o fine-tuning completo, todas as camadas do modelo s√£o ajustadas com base nos novos dados. Isso significa que os pesos das camadas profundas do modelo, que foram aprendidos durante o treinamento inicial, s√£o atualizados para se adequar √†s caracter√≠sticas espec√≠ficas do novo conjunto de dados. Matematicamente, essa abordagem pode ser descrita como a otimiza√ß√£o da seguinte fun√ß√£o de perda:
            """)
        
            st.latex(r'''
            L_{\text{fine-tuning}} = L_{\text{original}} + \lambda \sum_{i} w_i^2
            ''')
        
            st.write("""
            Onde:
            """)
          
            st.latex(r'''
            L_{\text{fine-tuning}}
            ''')
          
            st.write("""
            √© a fun√ß√£o de perda durante o fine-tuning;
            """)
          
            st.latex(r'''
            L_{\text{original}}
            ''')
          
            st.write("""
            representa a fun√ß√£o de perda original do modelo pr√©-treinado;
            """)
          
            st.latex(r'''
            \lambda
            ''')
          
            st.write("""
            √© o coeficiente de regulariza√ß√£o (no caso de utilizar a regulariza√ß√£o L2);
            """)
          
            st.latex(r'''
            w_i
            ''')
            st.write("""
            s√£o os pesos individuais que ser√£o atualizados durante o processo de fine-tuning (Friedrich et al., 2022; Al‚Äêrimy et al., 2023).
            """)
        
            st.write("""
            ### Benef√≠cios do Fine-Tuning Completo
        
            O fine-tuning completo oferece v√°rios benef√≠cios, especialmente quando o novo conjunto de dados difere substancialmente do conjunto no qual o modelo foi originalmente treinado. No caso da **classifica√ß√£o de melanomas** ou **rochas**, por exemplo, as caracter√≠sticas visuais dos dados podem ser muito diferentes das imagens do **ImageNet**, que incluem uma ampla variedade de objetos, animais e cen√°rios (Piotrowski & Napiorkowski, 2013; Sakizadeh et al., 2015).
            """)
        
            st.write("""
            Os principais benef√≠cios incluem:
            1. **Adapta√ß√£o Profunda**: Ao ajustar todas as camadas, o modelo consegue adaptar n√£o apenas as caracter√≠sticas gen√©ricas (como bordas e texturas), mas tamb√©m padr√µes mais complexos e espec√≠ficos do novo problema.
            2. **Melhoria da Precis√£o**: O fine-tuning completo geralmente resulta em melhorias significativas na precis√£o, especialmente quando os dados de treinamento s√£o limitados ou possuem caracter√≠sticas visuais √∫nicas (Friedrich et al., 2022; Al‚Äêrimy et al., 2023).
            3. **Generaliza√ß√£o Melhorada**: O processo de fine-tuning permite que o modelo generalize melhor para novos dados, uma vez que ele √© treinado para capturar padr√µes mais espec√≠ficos do novo dom√≠nio (Piotrowski & Napiorkowski, 2013; Sakizadeh et al., 2015).
            """)
        
            st.write("""
            ### Compara√ß√£o com o Fine-Tuning Parcial
        
            Em contraste com o fine-tuning completo, no qual todas as camadas s√£o atualizadas, o **fine-tuning parcial** mant√©m algumas das camadas iniciais congeladas, atualizando apenas as camadas finais. Essa abordagem pode ser √∫til quando o novo conjunto de dados √© semelhante ao conjunto de dados original no qual o modelo foi treinado. No entanto, quando os dados diferem substancialmente, o fine-tuning completo tende a ser mais eficaz, pois permite uma adapta√ß√£o mais profunda e personalizada (Al‚Äêrimy et al., 2023; Sakizadeh et al., 2015).
            """)
        
            st.write("""
            ### Efeitos do Fine-Tuning em Problemas Espec√≠ficos
        
            #### Classifica√ß√£o de Melanomas
        
            No caso da **classifica√ß√£o de melanomas**, o fine-tuning completo permite que o modelo identifique padr√µes visuais sutis na pele que podem ser indicativos de c√¢ncer. Essas caracter√≠sticas visuais podem incluir varia√ß√µes de textura, cor e bordas, que s√£o espec√≠ficas de imagens m√©dicas e diferem dos objetos comuns presentes em bases de dados gen√©ricas, como o **ImageNet** (Piotrowski & Napiorkowski, 2013; Friedrich et al., 2022).
            """)
        
            st.write("""
            #### Classifica√ß√£o de Rochas
        
            Para a **classifica√ß√£o de rochas vulc√¢nicas e plut√¥nicas**, o fine-tuning completo permite que o modelo capture padr√µes geol√≥gicos e estruturais espec√≠ficos, como varia√ß√µes de granula√ß√£o e texturas minerais. Novamente, esses padr√µes s√£o significativamente diferentes dos dados de objetos comuns, tornando o fine-tuning completo uma abordagem valiosa para melhorar a precis√£o da classifica√ß√£o (Friedrich et al., 2022; Al‚Äêrimy et al., 2023).
            """)
        
            st.write("""
            ### Considera√ß√µes Pr√°ticas
        
            Durante o processo de fine-tuning, √© importante monitorar o desempenho do modelo em um conjunto de valida√ß√£o para evitar o **overfitting**. Uma t√©cnica comum √© utilizar a **regulariza√ß√£o L2** ou o **dropout** para garantir que o modelo n√£o se ajuste excessivamente aos dados de treinamento (Piotrowski & Napiorkowski, 2013; Sakizadeh et al., 2015). Al√©m disso, a taxa de aprendizado deve ser cuidadosamente ajustada. Em muitos casos, utiliza-se uma taxa de aprendizado menor durante o fine-tuning para garantir que as atualiza√ß√µes dos pesos n√£o sejam muito dr√°sticas, preservando parte das informa√ß√µes aprendidas anteriormente.
            """)
        
            st.write("""
            ### Conclus√£o
        
            O fine-tuning completo √© uma t√©cnica eficaz para ajustar modelos pr√©-treinados, como a **ResNet18**, **ResNet50** ou **DenseNet121**, a novos conjuntos de dados. Ao permitir que todas as camadas do modelo sejam atualizadas, o fine-tuning completo oferece maior flexibilidade e precis√£o em problemas que diferem substancialmente dos dados originais. Quando combinado com outras t√©cnicas de regulariza√ß√£o, como a L2, o fine-tuning pode levar a modelos robustos e capazes de generalizar para novos dados, sendo uma ferramenta essencial no arsenal de t√©cnicas de aprendizado profundo.
            """)
        
            st.write("""
            ### Refer√™ncias
        
            - Al‚ÄêRIMY, B.; SAEED, F.; AL-SAREM, M.; ALBARRAK, A.; QASEM, S. An adaptive early stopping technique for densenet169-based knee osteoarthritis detection model. *Diagnostics*, 13(11), 1903, 2023. https://doi.org/10.3390/diagnostics13111903
            - FRIEDRICH, S. et al. Regularization approaches in clinical biostatistics: a review of methods and their applications. *Statistical Methods in Medical Research*, 32(2), 425-440, 2022. https://doi.org/10.1177/09622802221133557
            - PIOTROWSKI, A.; NAPIORKOWSKI, J. A comparison of methods to avoid overfitting in neural networks training in the case of catchment runoff modelling. *Journal of Hydrology*, 476, 97-111, 2013. https://doi.org/10.1016/j.jhydrol.2012.10.019
            - REZAEEZADE, A.; BATINA, L. Regularizers to the rescue: fighting overfitting in deeplearning-based side-channel analysis. 2022. https://doi.org/10.21203/rs.3.rs-2386625/v1
            - SAKIZADEH, M.; MALIAN, A.; AHMADPOUR, E. Groundwater quality modeling with a small data set. *Ground Water*, 54(1), 115-120, 2015. https://doi.org/10.1111/gwat.12317
            """)

    fine_tune = st.sidebar.checkbox("Fine-Tuning Completo", value=False)
    epochs = st.sidebar.slider("N√∫mero de √âpocas:", min_value=1, max_value=500, value=200, step=1)
    learning_rate = st.sidebar.select_slider("Taxa de Aprendizagem:", options=[0.1, 0.01, 0.001, 0.0001], value=0.0001)
    batch_size = st.sidebar.selectbox("Tamanho de Lote:", options=[4, 8, 16, 32, 64], index=2)
    train_split = st.sidebar.slider("Percentual de Treinamento:", min_value=0.5, max_value=0.9, value=0.7, step=0.05)
    valid_split = st.sidebar.slider("Percentual de Valida√ß√£o:", min_value=0.05, max_value=0.4, value=0.15, step=0.05)
    #________________________________________________________________________________________
    # Sidebar com o conte√∫do explicativo e f√≥rmula LaTeX
    with st.sidebar:
        with st.expander("Implementa√ß√£o da T√©cnica de Regulariza√ß√£o L2 (Weight Decay):"):
            st.write("""
            ### Introdu√ß√£o
            A regulariza√ß√£o L2, frequentemente referida como *weight decay*, √© uma t√©cnica amplamente utilizada para mitigar o **overfitting** 
            em modelos de aprendizado de m√°quina, especialmente em redes neurais profundas. O *overfitting* ocorre quando o modelo se ajusta n√£o apenas 
            aos padr√µes dos dados de treinamento, mas tamb√©m ao ru√≠do presente, o que compromete sua capacidade de generaliza√ß√£o para novos dados 
            (Piotrowski & Napiorkowski, 2013). A regulariza√ß√£o L2 adiciona um termo de penaliza√ß√£o √† fun√ß√£o de perda do modelo, o que resulta em uma 
            redu√ß√£o dos valores absolutos dos pesos, promovendo, assim, modelos mais simples e generaliz√°veis (Friedrich et al., 2022).
            Esta revis√£o visa fornecer uma vis√£o clara e t√©cnica da aplica√ß√£o da regulariza√ß√£o L2, discutindo seus efeitos, a interpreta√ß√£o do coeficiente de regulariza√ß√£o 
            """)
          
            st.latex(r'''
            \lambda
            ''')
          
            st.write("""
            e as implica√ß√µes da escolha desse par√¢metro.
            """)
          
            st.latex(r'''
            L_{\text{total}} = L_{\text{original}} + \lambda \sum_{i} w_i^2
            ''')
          
            st.write("""
            Onde:
            """) 
            
            st.latex(r'''
            L_{\text{total}}
            ''')
          
            st.write("""
            √© a perda total que o modelo busca minimizar;
            """)
            
            st.latex(r'''
            L_{\text{original}}
            ''')
          
            st.write("""
            √© a fun√ß√£o de perda original (como a perda de entropia cruzada); Œª √© o coeficiente de regulariza√ß√£o, que controla a penalidade aplicada aos pesos;
            """)
          
            st.latex(r'''
            w_i
            ''')
          
            st.write(""" 
            s√£o os pesos individuais do modelo (Al‚ÄêRimy et al., 2023).
            """)
          
            st.write("""
            Este termo adicional penaliza pesos grandes, for√ßando o modelo a priorizar solu√ß√µes que utilizam pesos menores, o que √© crucial para evitar 
            que o modelo memorize os dados de treinamento, promovendo maior capacidade de generaliza√ß√£o (Sakizadeh et al., 2015).
            """)
          
            st.write("""
            ### Fundamenta√ß√£o Te√≥rica
            A regulariza√ß√£o L2 tem uma base te√≥rica s√≥lida, sendo amplamente aplicada para controlar a complexidade do modelo. Ao adicionar o termo de penaliza√ß√£o, 
            a regulariza√ß√£o L2 ajuda a evitar o overfitting e melhora a estabilidade num√©rica do modelo (Friedrich et al., 2022). Isso √© particularmente importante 
            em redes neurais profundas, onde o n√∫mero de par√¢metros pode ser grande e a complexidade do modelo alta.
            """)
          
            st.write("""
            ### Efeitos da Regulariza√ß√£o L2
            A regulariza√ß√£o L2 controla a complexidade do modelo ao penalizar pesos grandes, o que √© particularmente √∫til em cen√°rios com muitos par√¢metros 
            ou dados ruidosos (Piotrowski & Napiorkowski, 2013). Al√©m de reduzir o overfitting, a L2 promove a estabilidade no treinamento, melhorando a consist√™ncia do desempenho 
            em dados de teste (Friedrich et al., 2022).
            """)
    
            st.write("""
            ### Interpreta√ß√£o e Efeitos Pr√°ticos de Œª
            """)
          
            st.write("""        
            A escolha do valor de Œª
            """)
      
            st.write("""
            influencia diretamente o comportamento do modelo:
            """)
    
            st.write("""
            #### Œª = 0
            """)
            st.write("""
            Quando Œª = 0, a regulariza√ß√£o L2 est√° desativada. Isso permite que o modelo ajuste-se livremente aos dados de treinamento, 
            aumentando o risco de overfitting, especialmente em conjuntos de dados pequenos ou ruidosos (Friedrich et al., 2022).
            """)
    
            st.write("""
            #### Œª = 0,01
            """)
            st.write("""
            Este √© um valor moderado, que penaliza de forma equilibrada os pesos do modelo. Essa configura√ß√£o ajuda a evitar o overfitting sem comprometer a capacidade do modelo de 
            aprender padr√µes relevantes (Al‚ÄêRimy et al., 2023).
            """)
    
            st.write("""
            #### Œª = 0,02 ou Œª = 0,03
            Esses valores aumentam a intensidade da penaliza√ß√£o, sendo √∫teis em cen√°rios com dados ruidosos ou em que o n√∫mero de par√¢metros √© alto em rela√ß√£o √† quantidade de dados 
            dispon√≠veis (Piotrowski & Napiorkowski, 2013). Contudo, deve-se monitorar o desempenho do modelo, pois valores elevados de Œª podem resultar em **underfitting**, 
            comprometendo a capacidade do modelo de capturar padr√µes complexos (Friedrich et al., 2022).
            """)
    
            st.write("""
            ### Conclus√£o
            A regulariza√ß√£o L2 √© uma t√©cnica poderosa no treinamento de redes neurais profundas, ajudando a mitigar o overfitting e a melhorar a capacidade de generaliza√ß√£o do modelo. 
            Ao penalizar pesos grandes, a L2 incentiva solu√ß√µes mais simples e robustas. No entanto, a escolha do valor de Œª √© crucial para garantir que o modelo consiga capturar 
            padr√µes complexos sem se ajustar excessivamente aos dados de treinamento.
            """)
    
            st.write("""
            ### Refer√™ncias
            - AL‚ÄêRIMY, B.; SAEED, F.; AL-SAREM, M.; ALBARRAK, A.; QASEM, S. An adaptive early stopping technique for densenet169-based knee osteoarthritis detection model. *Diagnostics*, 13(11), 1903, 2023. https://doi.org/10.3390/diagnostics13111903
            - FRIEDRICH, S. et al. Regularization approaches in clinical biostatistics: a review of methods and their applications. *Statistical Methods in Medical Research*, 32(2), 425-440, 2022. https://doi.org/10.1177/09622802221133557
            - PIOTROWSKI, A.; NAPIORKOWSKI, J. A comparison of methods to avoid overfitting in neural networks training in the case of catchment runoff modelling. *Journal of Hydrology*, 476, 97-111, 2013. https://doi.org/10.1016/j.jhydrol.2012.10.019
            - SAKIZADEH, M.; MALIAN, A.; AHMADPOUR, E. Groundwater quality modeling with a small data set. *Ground Water*, 54(1), 115-120, 2015. https://doi.org/10.1111/gwat.12317
            """)
    

  
    l2_lambda = st.sidebar.number_input("L2 Regularization (Weight Decay):", min_value=0.0, max_value=0.1, value=0.01, step=0.01)
    
    #________________________________________________________________________________________
    # Sidebar com o conte√∫do explicativo e f√≥rmula LaTeX
    with st.sidebar:
        with st.expander("Implementa√ß√£o da T√©cnica de Parada Precoce - Early Stopping:"):
            st.write("""
            #### Introdu√ß√£o
            A t√©cnica de **parada precoce** (ou *early stopping*) √© amplamente utilizada para mitigar o **overfitting** no treinamento de redes neurais profundas. 
            O overfitting ocorre quando o modelo se ajusta t√£o bem aos dados de treinamento que sua capacidade de generaliza√ß√£o para novos dados √© prejudicada. 
            O princ√≠pio da parada precoce √© interromper o treinamento quando o desempenho do modelo em um conjunto de valida√ß√£o n√£o apresenta melhorias significativas 
            ap√≥s um n√∫mero predefinido de √©pocas. Essa abordagem baseia-se na observa√ß√£o de que, ap√≥s certo ponto, melhorias no desempenho do modelo em dados de treinamento 
            n√£o resultam em melhorias em dados que o modelo ainda n√£o viu (Piotrowski & Napiorkowski, 2013; Al‚ÄêRimy et al., 2023).
            """)
      
            st.write("Matematicamente, a parada precoce pode ser descrita pela seguinte condi√ß√£o de interrup√ß√£o:")
            # F√≥rmulas matem√°ticas
            st.latex(r'''
            \text{Se } L_{\text{val}}(t) \geq L_{\text{val}}(t-1)
            ''')
            st.write("""
            por (p) √©pocas consecutivas, ent√£o interrompa o treinamento. Aqui,
            """)
            st.latex(r'''
            L_{\text{val}}(t)
            ''')
    
            st.write("""
            representa o valor da **fun√ß√£o de perda** no conjunto de valida√ß√£o na √©poca (t), e (p) √© o **par√¢metro de paci√™ncia**. 
            A paci√™ncia (p) define quanto tempo o treinamento deve continuar mesmo que n√£o haja melhorias imediatas. Se a perda n√£o melhorar por (p) √©pocas consecutivas, 
            o treinamento √© interrompido.
            """)
      
            st.write("""
            #### A Import√¢ncia da Paci√™ncia
            O par√¢metro de **paci√™ncia** define o n√∫mero de √©pocas consecutivas sem melhoria na m√©trica de valida√ß√£o que o modelo pode suportar antes de o treinamento ser interrompido. 
            A escolha do valor de paci√™ncia tem impacto direto no equil√≠brio entre **evitar o overfitting** e **permitir que o modelo continue aprendendo**. 
            """)
      
            st.write("##### Paci√™ncia = 0")
            st.write("""
            Um valor de paci√™ncia igual a zero implica que o treinamento ser√° interrompido imediatamente ap√≥s a primeira ocorr√™ncia de estagna√ß√£o na m√©trica de valida√ß√£o. 
            Isso pode ser √∫til em cen√°rios onde se deseja evitar qualquer risco de *overfitting*.
            """)
      
            st.write("##### Paci√™ncia ‚â• 1")
            st.write("""
            Uma paci√™ncia maior (como 1 ou 2) permite que o modelo continue sendo treinado mesmo ap√≥s pequenas flutua√ß√µes no desempenho, 
            o que pode ser ben√©fico em conjuntos de dados ruidosos (Sakizadeh et al., 2015).
            """)
      
            st.write("""
            #### Impacto do *Early Stopping* e da Paci√™ncia
            A configura√ß√£o do par√¢metro de paci√™ncia influencia diretamente a efici√™ncia do treinamento. Com uma paci√™ncia muito baixa, o treinamento pode ser interrompido de forma prematura, 
            mesmo que o modelo ainda tenha potencial de melhoria. Por outro lado, uma paci√™ncia muito alta pode permitir que o modelo se ajuste excessivamente aos dados de treinamento, 
            levando ao *overfitting* (Sakizadeh et al., 2015).
            """)
      
            st.write("""
            #### Exemplos de Aplica√ß√£o
            Um exemplo pr√°tico de uso da parada precoce √© em tarefas de **classifica√ß√£o de imagens**. Durante o treinamento de um modelo para detec√ß√£o de melanoma, se a acur√°cia no conjunto de valida√ß√£o 
            n√£o melhorar ap√≥s um determinado n√∫mero de √©pocas, o early stopping √© acionado.
            """)
      
            st.write("""
            #### Integra√ß√£o com Outras T√©cnicas de Regulariza√ß√£o
            A parada precoce pode ser usada em conjunto com outras t√©cnicas de regulariza√ß√£o, como a **inje√ß√£o de ru√≠do** e a regulariza√ß√£o **L1/L2**, 
            para melhorar a robustez do modelo e sua capacidade de generaliza√ß√£o (Friedrich et al., 2022). 
            A combina√ß√£o dessas t√©cnicas ajuda a evitar que o modelo se ajuste excessivamente aos dados de treinamento, principalmente em cen√°rios com volumes limitados de dados.
            """)
      
            st.write("""
            #### Conclus√£o
            A **parada precoce** √© uma t√©cnica eficaz para evitar o *overfitting* no treinamento de redes neurais profundas. O valor da paci√™ncia desempenha um papel cr√≠tico, 
            permitindo o equil√≠brio entre **efici√™ncia computacional** e **capacidade de aprendizado**. Al√©m disso, a combina√ß√£o da parada precoce com outras t√©cnicas de regulariza√ß√£o 
            pode melhorar ainda mais o desempenho do modelo.
            """)
      
            st.write("""
            #### Refer√™ncias
            - PIOTROWSKI, A.; NAPIORKOWSKI, J. A comparison of methods to avoid overfitting in neural networks training in the case of catchment runoff modelling. *Journal of Hydrology*, v. 476, p. 97-111, 2013. https://doi.org/10.1016/j.jhydrol.2012.10.019.
            - AL‚ÄêRIMY, B. et al. An adaptive early stopping technique for densenet169-based knee osteoarthritis detection model. *Diagnostics*, v. 13, n. 11, p. 1903, 2023. https://doi.org/10.3390/diagnostics13111903.
            - SAKIZADEH, M.; MALIAN, A.; AHMADPOUR, E. Groundwater quality modeling with a small data set. *Ground Water*, v. 54, n. 1, p. 115-120, 2015. https://doi.org/10.1111/gwat.12317.
            - FRIEDRICH, S. et al. Regularization approaches in clinical biostatistics: a review of methods and their applications. *Statistical Methods in Medical Research*, v. 32, n. 2, p. 425-440, 2022. https://doi.org/10.1177/09622802221133557.
            """)


    #________________________________________________________________________________________
    patience = st.sidebar.number_input("Paci√™ncia para Early Stopping:", min_value=1, max_value=10, value=3, step=1)

    #____________________________________________________________________________________________
    with st.sidebar:
        with st.expander("Perda Ponderada para Classes Desbalanceadas:"):
            st.write("""
            ### Perda Ponderada para Classes Desbalanceadas
        
            A t√©cnica de **perda ponderada** para lidar com **classes desbalanceadas** √© amplamente utilizada em **aprendizado de m√°quina**, especialmente em redes neurais, para tratar problemas onde o n√∫mero de amostras entre as classes de um conjunto de dados n√£o √© equilibrado. O desbalanceamento ocorre em diversos dom√≠nios, como detec√ß√£o de fraudes, diagn√≥stico de doen√ßas e classifica√ß√£o de imagens. O principal objetivo da perda ponderada √© ajustar a fun√ß√£o de perda, atribuindo diferentes pesos √†s classes, de forma que o impacto das classes minorit√°rias (menos representadas) seja ampliado e o impacto das classes majorit√°rias seja reduzido. Isso ajuda o modelo a aprender de forma mais eficaz em cen√°rios onde o desequil√≠brio entre as classes pode levar ao **overfitting** nas classes majorit√°rias e √† **sub-representa√ß√£o** das classes minorit√°rias (Buda et al., 2018).
        
            ### Motiva√ß√£o e Justificativa Cient√≠fica
        
            Em um cen√°rio de classifica√ß√£o de imagens, se o modelo for treinado com uma quantidade muito maior de amostras de uma classe (classe majorit√°ria) em rela√ß√£o a outra (classe minorit√°ria), o modelo tende a ser enviesado para a classe majorit√°ria. Isso ocorre porque o objetivo padr√£o da maioria das fun√ß√µes de perda, como a **entropia cruzada**, √© minimizar a soma dos erros. Em um conjunto de dados desbalanceado, essa minimiza√ß√£o pode ser alcan√ßada simplesmente classificando todas as amostras como pertencentes √† classe majorit√°ria, resultando em alta acur√°cia geral, mas com desempenho ruim na classe minorit√°ria. Para resolver esse problema, atribui-se um peso maior √† classe minorit√°ria, for√ßando a fun√ß√£o de perda a penalizar mais fortemente os erros cometidos nessa classe (Buda et al., 2018).
        
            ### Implementa√ß√£o no C√≥digo
        
            No c√≥digo, a implementa√ß√£o da perda ponderada √© feita utilizando a fun√ß√£o de perda **CrossEntropyLoss** do PyTorch, que suporta a aplica√ß√£o de pesos √†s classes. Esses pesos s√£o calculados com base na **frequ√™ncia das classes** no conjunto de treinamento. Classes com menos amostras recebem pesos maiores, enquanto classes com mais amostras recebem pesos menores, balanceando o impacto de ambas durante o treinamento do modelo.
        
            """)
            
            st.write("**criterion = nn.CrossEntropyLoss(weight=class_weights)**")
            
            st.write("""
            No trecho de c√≥digo acima, o vetor `targets` coleta os r√≥tulos das amostras no conjunto de treino e a fun√ß√£o `np.bincount(targets)` conta quantas vezes cada classe aparece, resultando em um vetor `class_counts`, onde cada √≠ndice corresponde √† quantidade de amostras de uma classe espec√≠fica (Buda et al., 2018).
        
            ### Etapas do Processo
        
            1. **C√°lculo das Frequ√™ncias das Classes**: As frequ√™ncias de cada classe s√£o calculadas usando `np.bincount`. Classes menos representadas recebem pesos maiores.
            2. **Ajuste para Evitar Divis√£o por Zero**: Um pequeno valor (1e-6) √© adicionado para evitar divis√£o por zero quando uma classe n√£o tem nenhuma amostra.
            3. **C√°lculo dos Pesos Inversos**: A partir da frequ√™ncia, os pesos s√£o calculados tomando o inverso da frequ√™ncia de cada classe. Isso aumenta a penaliza√ß√£o dos erros nas classes minorit√°rias.
            4. **Fun√ß√£o de Perda Ponderada**: A fun√ß√£o de perda `nn.CrossEntropyLoss(weight=class_weights)` usa os pesos calculados, penalizando mais fortemente os erros das classes minorit√°rias.
        
            ### Impacto e Efic√°cia da Perda Ponderada
        
            A **perda ponderada** ajusta o aprendizado do modelo, incentivando a penaliza√ß√£o dos erros cometidos nas classes minorit√°rias. Estudos demonstram que essa t√©cnica √© eficaz em aumentar a **recall** das classes minorit√°rias, sem comprometer drasticamente a precis√£o das classes majorit√°rias (Buda et al., 2018). No entanto, a aplica√ß√£o da perda ponderada pode tornar o treinamento mais **sens√≠vel √† escolha dos hiperpar√¢metros**, como a **taxa de aprendizado**, pois o modelo passa a ser fortemente influenciado pelas amostras menos representativas.
        
            ### Conclus√£o
        
            A implementa√ß√£o da **perda ponderada** no c√≥digo √© uma abordagem robusta para lidar com **classes desbalanceadas**. Ao ajustar os pesos da fun√ß√£o de perda com base nas frequ√™ncias das classes, o modelo consegue equilibrar melhor o aprendizado entre as classes majorit√°rias e minorit√°rias, evitando vieses que favorecem a classe mais representada no conjunto de dados (Buda et al., 2018).
        
            ### Refer√™ncias
        
            - Buda, M., Maki, A., & Mazurowski, M. (2018). A systematic study of the class imbalance problem in convolutional neural networks. *Neural Networks*, 106, 249-259. https://doi.org/10.1016/j.neunet.2018.07.011
            """)

    use_weighted_loss = st.sidebar.checkbox("Usar Perda Ponderada para Classes Desbalanceadas", value=False)
    
    # Se√ß√£o de Informa√ß√µes Acad√™micas das Doen√ßas
    st.sidebar.markdown("---")
    st.sidebar.title("üéì Informa√ß√µes Acad√™micas")
    st.sidebar.markdown("Consulte informa√ß√µes detalhadas sobre doen√ßas bucais com refer√™ncias do PubMed:")
    
    # Lista de doen√ßas dispon√≠veis
    diseases = {
        "Gangivoestomatite": "gangivoestomatite",
        "Aftas": "aftas", 
        "Herpes Labial": "herpes_labial",
        "L√≠quen Plano Oral": "liquen_plano_oral",
        "Candid√≠ase Oral": "candid√≠ase_oral",
        "C√¢ncer de Boca": "cancer_boca",
        "C√¢ncer Oral": "cancer_oral"
    }
    
    # Seletor de doen√ßa
    selected_disease = st.sidebar.selectbox(
        "Selecione uma doen√ßa para consultar:",
        list(diseases.keys()),
        help="Escolha uma doen√ßa para ver informa√ß√µes detalhadas e refer√™ncias acad√™micas"
    )
    
    # Bot√£o para mostrar informa√ß√µes
    if st.sidebar.button("üìñ Consultar Informa√ß√µes Acad√™micas", type="primary"):
        disease_key = diseases[selected_disease]
        # Armazenar na sess√£o para mostrar no main content
        st.session_state.show_disease_modal = True
        st.session_state.selected_disease = selected_disease
        st.session_state.disease_key = disease_key
    
    st.sidebar.image("eu.jpg", width=80)
   
    st.sidebar.write("""
    Produzido pelo:
    
    Projeto Geomaker + IA 
    
    https://doi.org/10.5281/zenodo.13925454
    - Professor: Marcelo Claro.
    Contatos: marceloclaro@gmail.com
    Whatsapp: (88)981587145
    Instagram: [marceloclaro.geomaker](https://www.instagram.com/marceloclaro.geomaker/)
    
    """)
     # _____________________________________________
    # Controle de √Åudio
    st.sidebar.title("Controle de √Åudio")
    
    # Dicion√°rio de arquivos de √°udio, com nomes amig√°veis mapeando para o caminho do arquivo
    mp3_files = {
        "√Åudio explicativo para Leigos": "leigo.mp3",
        "√Åudio explicativo para treinamentos de poucos dados": "bucal.mp3",
    }
    
    # Lista de arquivos MP3 para sele√ß√£o
    selected_mp3 = st.sidebar.radio("Escolha um √°udio explicativo:", options=list(mp3_files.keys()))
    
    # Controle de op√ß√£o de repeti√ß√£o
    loop = st.sidebar.checkbox("Repetir √°udio")
    
    # Bot√£o de Play para iniciar o √°udio
    play_button = st.sidebar.button("Play")
    
    # Placeholder para o player de √°udio
    audio_placeholder = st.sidebar.empty()
    
    # Fun√ß√£o para verificar se o arquivo existe
    def check_file_exists(mp3_path):
        if not os.path.exists(mp3_path):
            st.sidebar.error(f"Arquivo {mp3_path} n√£o encontrado.")
            return False
        return True
    
    # Se o bot√£o Play for pressionado e um arquivo de √°udio estiver selecionado
    if play_button and selected_mp3:
        mp3_path = mp3_files[selected_mp3]
        
        # Verifica√ß√£o da exist√™ncia do arquivo
        if check_file_exists(mp3_path):
            try:
                # Abrindo o arquivo de √°udio no modo bin√°rio
                with open(mp3_path, "rb") as audio_file:
                    audio_bytes = audio_file.read()
                    
                    # Codificando o arquivo em base64 para embutir no HTML
                    audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
                    
                    # Controle de loop (repeti√ß√£o)
                    loop_attr = "loop" if loop else ""
                    
                    # Gerando o player de √°udio em HTML
                    audio_html = f"""
                    <audio id="audio-player" controls autoplay {loop_attr}>
                      <source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3">
                      Seu navegador n√£o suporta o elemento de √°udio.
                    </audio>
                    """
                    
                    # Inserindo o player de √°udio na interface
                    audio_placeholder.markdown(audio_html, unsafe_allow_html=True)
            
            except FileNotFoundError:
                st.sidebar.error(f"Arquivo {mp3_path} n√£o encontrado.")
            except Exception as e:
                st.sidebar.error(f"Erro ao carregar o arquivo: {str(e)}")
    #______________________________________________________________________________________-


    # Verificar se a soma dos splits √© v√°lida
    if train_split + valid_split > 0.95:
        st.sidebar.error("A soma dos splits de treinamento e valida√ß√£o deve ser menor ou igual a 0.95.")

    # Upload do arquivo ZIP
    zip_file = st.file_uploader("Upload do arquivo ZIP com as imagens", type=["zip"])
    
    # Mostrar modal de informa√ß√µes acad√™micas se solicitado
    if st.session_state.get('show_disease_modal', False):
        show_disease_modal(
            st.session_state.get('selected_disease', ''),
            st.session_state.get('disease_key', '')
        )
        # Limpar o estado ap√≥s mostrar
        st.session_state.show_disease_modal = False

    if zip_file is not None and num_classes > 0 and train_split + valid_split <= 0.95:
        temp_dir = tempfile.mkdtemp()
        zip_path = os.path.join(temp_dir, "uploaded.zip")
        with open(zip_path, "wb") as f:
            f.write(zip_file.read())
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(temp_dir)
        data_dir = temp_dir

        st.write("Iniciando o treinamento supervisionado...")
        model_data = train_model(data_dir, num_classes, model_name, fine_tune, epochs, learning_rate, batch_size, train_split, valid_split, use_weighted_loss, l2_lambda, patience)

        if model_data is None:
            st.error("Erro no treinamento do modelo.")
            shutil.rmtree(temp_dir)
            return

        model, classes = model_data
        st.success("Treinamento conclu√≠do!")

        # Extrair caracter√≠sticas usando o modelo pr√©-treinado (sem a camada final)
        st.write("Extraindo caracter√≠sticas para clustering...")
        # Remover a √∫ltima camada do modelo para obter embeddings
        if model_name.startswith('ResNet'):
            feature_extractor = nn.Sequential(*list(model.children())[:-1])
        elif model_name.startswith('DenseNet'):
            feature_extractor = nn.Sequential(*list(model.features))
            feature_extractor.add_module('global_pool', nn.AdaptiveAvgPool2d((1,1)))
        else:
            st.error("Modelo n√£o suportado para extra√ß√£o de caracter√≠sticas.")
            return

        feature_extractor = feature_extractor.to(device)
        feature_extractor.eval()

        # Carregar o dataset completo para extra√ß√£o de caracter√≠sticas
        full_dataset = datasets.ImageFolder(root=data_dir, transform=test_transforms)
        features, labels = extract_features(full_dataset, feature_extractor, batch_size)

        # Aplicar algoritmos de clustering
        st.write("Aplicando algoritmos de clustering...")
        features_reshaped = features.reshape(len(features), -1)
        hierarchical_labels, kmeans_labels = perform_clustering(features_reshaped, num_classes)

        # Avaliar e exibir os resultados
        st.write("Avaliando os resultados do clustering...")
        evaluate_clustering(labels, hierarchical_labels, "Clustering Hier√°rquico")
        evaluate_clustering(labels, kmeans_labels, "K-Means Clustering")

        # Visualizar clusters
        visualize_clusters(features_reshaped, labels, hierarchical_labels, kmeans_labels, classes)

        # Avalia√ß√£o de uma imagem individual
        evaluate = st.radio("Deseja avaliar uma imagem?", ("Sim", "N√£o"))
        if evaluate == "Sim":
            eval_image_file = st.file_uploader("Fa√ßa upload da imagem para avalia√ß√£o", type=["png", "jpg", "jpeg", "bmp", "gif"])
            if eval_image_file is not None:
                eval_image_file.seek(0)
                try:
                    eval_image = Image.open(eval_image_file).convert("RGB")
                except Exception as e:
                    st.error(f"Erro ao abrir a imagem: {e}")
                    return

                st.image(eval_image, caption='Imagem para avalia√ß√£o', use_column_width=True)
                class_name, confidence = evaluate_image(model, eval_image, classes)
                st.write(f"**Classe Predita:** {class_name}")
                st.write(f"**Confian√ßa:** {confidence:.4f}")
                
                # Bot√£o para ver informa√ß√µes acad√™micas da doen√ßa predita
                col1, col2 = st.columns([1, 1])
                with col1:
                    if st.button(f"üìñ Ver Informa√ß√µes sobre {class_name}", type="secondary"):
                        disease_key = get_disease_key(class_name)
                        show_disease_modal(class_name, disease_key)
                
                with col2:
                    # Visualizar ativa√ß√µes
                    if st.button("üîç Visualizar Ativa√ß√µes (Grad-CAM)", type="secondary"):
                        visualize_activations(model, eval_image, classes)

        # Limpar o diret√≥rio tempor√°rio
        shutil.rmtree(temp_dir)

if __name__ == "__main__":
    main()
